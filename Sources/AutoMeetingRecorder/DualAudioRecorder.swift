import Foundation
import AVFoundation
import ScreenCaptureKit
import CoreAudio

@available(macOS 13.0, *)
class DualAudioRecorder: NSObject {
    // MARK: - Properties
    
    private var stream: SCStream?
    private var microphoneEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    private var systemAudioFile: AVAudioFile?

    private var isRecording = false
    private var recordingStartTime: Date?
    private var currentRecordingBaseName: String?

    private let microphoneDirectory: URL
    private let systemDirectory: URL
    private let mixDirectory: URL
    private let queue = DispatchQueue(label: "com.meetingrecorder.audio", qos: .userInitiated)

    var onRecordingStopped: (() -> Void)?

    // MARK: - Init

    override init() {
        let paths = AppPaths.shared
        self.microphoneDirectory = paths.microphoneRecordingsDirectory
        self.systemDirectory = paths.systemRecordingsDirectory
        self.mixDirectory = paths.mixedRecordingsDirectory

        super.init()

        print("ðŸŽ™ï¸  DualAudioRecorder Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
        print("ðŸ“ ÐŸÐ°Ð¿ÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ:")
        print("   ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: \(microphoneDirectory.path)")
        print("   ðŸ’» Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°: \(systemDirectory.path)")
        print("   ðŸŽ§ ÐœÐ¸ÐºÑÑ‹: \(mixDirectory.path)")
    }
    
    // MARK: - Public Methods
    
    func startRecording() async throws {
        guard !isRecording else {
            print("âš ï¸  Ð—Ð°Ð¿Ð¸ÑÑŒ ÑƒÐ¶Ðµ Ð¸Ð´Ñ‘Ñ‚")
            return
        }
        
        print("\nðŸŽ¬ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ...")
        
        // 1. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½
        try setupMicrophone()
        
        // 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾
        let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
        
        // 3. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        let config = SCStreamConfiguration()
        config.capturesAudio = true
        config.sampleRate = 48000
        config.channelCount = 2
        
        // Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ (Ð·Ð°Ñ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÑ‘ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ Ð°ÑƒÐ´Ð¸Ð¾)
        let filter = SCContentFilter(display: content.displays.first!, excludingWindows: [])
        
        // 4. Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        stream = SCStream(filter: filter, configuration: config, delegate: self)
        
        // 5. Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸
        try createAudioFiles()
        
        // 6. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ñ‹Ð²Ð¾Ð´ Ð°ÑƒÐ´Ð¸Ð¾
        try stream?.addStreamOutput(self, type: .audio, sampleHandlerQueue: queue)
        
        // 7. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        try await stream?.startCapture()
        
        // 8. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½
        try microphoneEngine?.start()
        
        isRecording = true
        recordingStartTime = Date()
        
        print("âœ… Ð—Ð°Ð¿Ð¸ÑÑŒ Ð½Ð°Ñ‡Ð°Ð»Ð°ÑÑŒ!")
        print("   ðŸ“º Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð·Ð²ÑƒÐº: Ð·Ð°Ñ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ")
        print("   ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½")
    }
    
    func stopRecording() {
        guard isRecording else {
            print("âš ï¸  Ð—Ð°Ð¿Ð¸ÑÑŒ Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°")
            return
        }

        print("\nâ¹ï¸  ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ...")

        let microphoneURL = audioFile?.url
        let systemURL = systemAudioFile?.url
        let baseName = currentRecordingBaseName

        Task {
            try? await stream?.stopCapture()
            stream = nil
        }

        microphoneEngine?.stop()
        microphoneEngine?.inputNode.removeTap(onBus: 0)
        microphoneEngine = nil
        
        if let startTime = recordingStartTime {
            let duration = Date().timeIntervalSince(startTime)
            print("â±ï¸  Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: \(formatDuration(duration))")
        }
        
        if let audioFile = audioFile {
            let filename = audioFile.url.lastPathComponent
            let fileSize = getFileSize(audioFile.url)
            print("âœ… ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: \(filename)")
            print("   Ð Ð°Ð·Ð¼ÐµÑ€: \(fileSize)")
        }
        
        if let systemFile = systemAudioFile {
            let filename = systemFile.url.lastPathComponent
            let fileSize = getFileSize(systemFile.url)
            print("âœ… Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾: \(filename)")
            print("   Ð Ð°Ð·Ð¼ÐµÑ€: \(fileSize)")
        }

        print("ðŸ“‚ ÐŸÐ°Ð¿ÐºÐ¸ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ:")
        print("   ðŸŽ¤ \(microphoneDirectory.lastPathComponent): \(microphoneDirectory.path)")
        print("   ðŸ’» \(systemDirectory.lastPathComponent): \(systemDirectory.path)")
        print("   ðŸŽ§ \(mixDirectory.lastPathComponent): \(mixDirectory.path)")

        if let microphoneURL, let systemURL, let baseName {
            print("ðŸŽšï¸ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð´Ð»Ñ \(baseName)...")
            Task.detached { [weak self] in
                await self?.mixDownRecordings(
                    microphoneURL: microphoneURL,
                    systemURL: systemURL,
                    baseName: baseName
                )
            }
        }

        isRecording = false
        audioFile = nil
        systemAudioFile = nil
        recordingStartTime = nil
        currentRecordingBaseName = nil

        onRecordingStopped?()
    }
    
    // MARK: - Private Methods
    
    private func setupMicrophone() throws {
        microphoneEngine = AVAudioEngine()
        guard let engine = microphoneEngine else { return }
        
        let inputNode = engine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        
        print("ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: \(format.sampleRate)Hz, \(format.channelCount) ÐºÐ°Ð½Ð°Ð»Ð¾Ð²")
        
        // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ tap Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: format) { [weak self] buffer, _ in
            self?.writeMicrophoneBuffer(buffer)
        }
    }
    
    private func writeMicrophoneBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = audioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°: \(error.localizedDescription)")
            }
        }
    }
    
    private func writeSystemAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = systemAudioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾: \(error.localizedDescription)")
            }
        }
    }
    
    private func createAudioFiles() throws {
        let timestamp = ISO8601DateFormatter().string(from: Date())
            .replacingOccurrences(of: ":", with: "-")
            .replacingOccurrences(of: ".", with: "-")
            .prefix(19)
        let baseName = String(timestamp)
        currentRecordingBaseName = baseName

        // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        guard let micFormat = microphoneEngine?.inputNode.outputFormat(forBus: 0) else {
            throw NSError(domain: "DualAudioRecorder", code: 1,
                         userInfo: [NSLocalizedDescriptionKey: "ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°"])
        }

        // Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        let micFilename = "microphone_\(baseName).wav"
        let micURL = microphoneDirectory.appendingPathComponent(micFilename)
        audioFile = try AVAudioFile(forWriting: micURL, settings: micFormat.settings)
        print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½ Ñ„Ð°Ð¹Ð» Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°: \(micFilename)")

        // Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ (ÑÑ‚ÐµÑ€ÐµÐ¾)
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 48000.0,
            AVNumberOfChannelsKey: 2,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]

        let sysFilename = "system_\(baseName).wav"
        let sysURL = systemDirectory.appendingPathComponent(sysFilename)
        systemAudioFile = try AVAudioFile(forWriting: sysURL, settings: settings)
        print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½ Ñ„Ð°Ð¹Ð» ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: \(sysFilename)")
    }

    private func mixDownRecordings(microphoneURL: URL, systemURL: URL, baseName: String) async {
        print("ðŸŽšï¸ Ð¡Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð´Ð¾Ñ€Ð¾Ð¶ÐµÐº Ð´Ð»Ñ \(baseName) Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾...")
        do {
            let outputURL = try await mixAudioFiles(
                microphoneURL: microphoneURL,
                systemURL: systemURL,
                baseName: baseName
            )
            let fileSize = getFileSize(outputURL)
            print("ðŸŽ§ Ð¡Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: \(outputURL.lastPathComponent)")
            print("   Ð Ð°Ð·Ð¼ÐµÑ€: \(fileSize)")
            print("   ÐŸÑƒÑ‚ÑŒ: \(outputURL.path)")
            print("â˜ï¸ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¼Ð¸ÐºÑÐ° Ð² Supabase (ÐµÑÐ»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¾)...")

            Task.detached(priority: .background) {
                do {
                    try await SupabaseUploader.shared.uploadMix(at: outputURL, baseName: baseName)
                    print("ðŸ“¤ Supabase: Ð¼Ð¸ÐºÑ \(outputURL.lastPathComponent) Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½")
                } catch {
                    print("âš ï¸ Supabase: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ \(outputURL.lastPathComponent): \(error.localizedDescription)")
                    print("   ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Ð¾Ñ„Ð»Ð°Ð¹Ð½, Ñ„Ð°Ð¹Ð» Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾.")
                }
            }
        } catch {
            print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ Ð´Ð¾Ñ€Ð¾Ð¶ÐµÐº: \(error.localizedDescription)")
        }
    }

    private func mixAudioFiles(microphoneURL: URL, systemURL: URL, baseName: String) async throws -> URL {
        let outputURL = mixDirectory.appendingPathComponent("mix_\(baseName).m4a")
        if FileManager.default.fileExists(atPath: outputURL.path) {
            try FileManager.default.removeItem(at: outputURL)
        }

        let composition = AVMutableComposition()

        let microphoneAsset = AVURLAsset(url: microphoneURL)
        let systemAsset = AVURLAsset(url: systemURL)

        let microphoneTrack = try await loadAudioTrack(from: microphoneAsset)
        let systemTrack = try await loadAudioTrack(from: systemAsset)

        guard let microphoneCompositionTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ), let systemCompositionTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            throw NSError(
                domain: "DualAudioRecorder",
                code: 3,
                userInfo: [NSLocalizedDescriptionKey: "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´Ð¾Ñ€Ð¾Ð¶ÐºÐ¸ Ð´Ð»Ñ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ"]
            )
        }

        let microphoneDuration = try await loadDuration(for: microphoneAsset)
        let systemDuration = try await loadDuration(for: systemAsset)

        try microphoneCompositionTrack.insertTimeRange(
            CMTimeRange(start: .zero, duration: microphoneDuration),
            of: microphoneTrack,
            at: .zero
        )

        try systemCompositionTrack.insertTimeRange(
            CMTimeRange(start: .zero, duration: systemDuration),
            of: systemTrack,
            at: .zero
        )

        let audioMix = AVMutableAudioMix()
        let microphoneParameters = AVMutableAudioMixInputParameters(track: microphoneCompositionTrack)
        microphoneParameters.setVolume(1.0, at: .zero)
        let systemParameters = AVMutableAudioMixInputParameters(track: systemCompositionTrack)
        systemParameters.setVolume(1.0, at: .zero)
        audioMix.inputParameters = [microphoneParameters, systemParameters]

        guard let exporter = AVAssetExportSession(
            asset: composition,
            presetName: AVAssetExportPresetAppleM4A
        ) else {
            throw NSError(
                domain: "DualAudioRecorder",
                code: 4,
                userInfo: [NSLocalizedDescriptionKey: "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ñ‘Ñ€ Ð´Ð»Ñ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ"]
            )
        }

        exporter.audioMix = audioMix
        exporter.outputURL = outputURL
        exporter.outputFileType = .m4a

        let maxDuration = CMTimeMaximum(microphoneDuration, systemDuration)
        if maxDuration.isNumeric && maxDuration.isValid && !maxDuration.isIndefinite {
            exporter.timeRange = CMTimeRange(start: .zero, duration: maxDuration)
        }

        try await export(exporter)
        return outputURL
    }

    private func loadAudioTrack(from asset: AVURLAsset) async throws -> AVAssetTrack {
        try await withCheckedThrowingContinuation { continuation in
            asset.loadValuesAsynchronously(forKeys: ["tracks"]) {
                var error: NSError?
                let status = asset.statusOfValue(forKey: "tracks", error: &error)
                switch status {
                case .loaded:
                    if let track = asset.tracks(withMediaType: .audio).first {
                        continuation.resume(returning: track)
                    } else {
                        continuation.resume(throwing: NSError(
                            domain: "DualAudioRecorder",
                            code: 5,
                            userInfo: [NSLocalizedDescriptionKey: "ÐÑƒÐ´Ð¸Ð¾Ð´Ð¾Ñ€Ð¾Ð¶ÐºÐ° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚"]
                        ))
                    }
                case .failed:
                    continuation.resume(throwing: error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 6,
                        userInfo: [NSLocalizedDescriptionKey: "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð¾Ñ€Ð¾Ð¶ÐºÑƒ"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 7,
                        userInfo: [NSLocalizedDescriptionKey: "Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¾Ñ€Ð¾Ð¶ÐºÐ¸ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð°"]
                    ))
                default:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 8,
                        userInfo: [NSLocalizedDescriptionKey: "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð´Ð¾Ñ€Ð¾Ð¶ÐºÐ¸"]
                    ))
                }
            }
        }
    }

    private func loadDuration(for asset: AVURLAsset) async throws -> CMTime {
        try await withCheckedThrowingContinuation { continuation in
            asset.loadValuesAsynchronously(forKeys: ["duration"]) {
                var error: NSError?
                let status = asset.statusOfValue(forKey: "duration", error: &error)
                switch status {
                case .loaded:
                    continuation.resume(returning: asset.duration)
                case .failed:
                    continuation.resume(throwing: error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 9,
                        userInfo: [NSLocalizedDescriptionKey: "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 10,
                        userInfo: [NSLocalizedDescriptionKey: "ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð¾"]
                    ))
                default:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 11,
                        userInfo: [NSLocalizedDescriptionKey: "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"]
                    ))
                }
            }
        }
    }

    private func export(_ exporter: AVAssetExportSession) async throws {
        try await withCheckedThrowingContinuation { continuation in
            exporter.exportAsynchronously {
                switch exporter.status {
                case .completed:
                    continuation.resume()
                case .failed:
                    continuation.resume(throwing: exporter.error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 12,
                        userInfo: [NSLocalizedDescriptionKey: "Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»ÑÑ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 13,
                        userInfo: [NSLocalizedDescriptionKey: "Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¾Ñ‚Ð¼ÐµÐ½Ñ‘Ð½"]
                    ))
                default:
                    break
                }
            }
        }
    }
    
    private func getFileSize(_ url: URL) -> String {
        guard let attributes = try? FileManager.default.attributesOfItem(atPath: url.path),
              let fileSize = attributes[.size] as? Int64 else {
            return "unknown"
        }
        
        let formatter = ByteCountFormatter()
        formatter.countStyle = .file
        return formatter.string(fromByteCount: fileSize)
    }
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    deinit {
        if isRecording {
            stopRecording()
        }
    }
}

// MARK: - SCStreamDelegate

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("âŒ ÐŸÐ¾Ñ‚Ð¾Ðº Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹: \(error.localizedDescription)")
        stopRecording()
    }
}

// MARK: - SCStreamOutput

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamOutput {
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard isRecording, type == .audio else { return }
        
        // ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ CMSampleBuffer Ð² AVAudioPCMBuffer
        guard let audioBuffer = createPCMBuffer(from: sampleBuffer) else { return }
        
        writeSystemAudioBuffer(audioBuffer)
    }
    
    private func createPCMBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer),
              let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) else {
            return nil
        }
        
        let format = AVAudioFormat(streamDescription: audioStreamBasicDescription)!
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        CMSampleBufferCopyPCMDataIntoAudioBufferList(
            sampleBuffer,
            at: 0,
            frameCount: Int32(frameCount),
            into: buffer.mutableAudioBufferList
        )
        
        return buffer
    }
}
