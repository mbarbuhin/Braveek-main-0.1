import Foundation
import AVFoundation
import ScreenCaptureKit
import CoreAudio

@available(macOS 13.0, *)
class DualAudioRecorder: NSObject {
    // MARK: - Properties
    
    private var stream: SCStream?
    private var microphoneEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    private var systemAudioFile: AVAudioFile?

    private var isRecording = false
    private var recordingStartTime: Date?

    private let outputDirectory: URL
    private let queue = DispatchQueue(label: "com.meetingrecorder.audio", qos: .userInitiated)

    var onRecordingStopped: (() -> Void)?

    // MARK: - Init

    override init() {
        self.outputDirectory = AppPaths.shared.recordingsDirectory

        super.init()

        print("ðŸŽ™ï¸  DualAudioRecorder Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
        print("ðŸ“ Ð—Ð°Ð¿Ð¸ÑÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ: \(outputDirectory.path)")
    }
    
    // MARK: - Public Methods
    
    func startRecording() async throws {
        guard !isRecording else {
            print("âš ï¸  Ð—Ð°Ð¿Ð¸ÑÑŒ ÑƒÐ¶Ðµ Ð¸Ð´Ñ‘Ñ‚")
            return
        }
        
        print("\nðŸŽ¬ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ...")
        
        // 1. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½
        try setupMicrophone()
        
        // 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾
        let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
        
        // 3. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        let config = SCStreamConfiguration()
        config.capturesAudio = true
        config.sampleRate = 48000
        config.channelCount = 2
        
        // Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ (Ð·Ð°Ñ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÑ‘ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ Ð°ÑƒÐ´Ð¸Ð¾)
        let filter = SCContentFilter(display: content.displays.first!, excludingWindows: [])
        
        // 4. Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        stream = SCStream(filter: filter, configuration: config, delegate: self)
        
        // 5. Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸
        try createAudioFiles()
        
        // 6. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ñ‹Ð²Ð¾Ð´ Ð°ÑƒÐ´Ð¸Ð¾
        try stream?.addStreamOutput(self, type: .audio, sampleHandlerQueue: queue)
        
        // 7. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾
        try await stream?.startCapture()
        
        // 8. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½
        try microphoneEngine?.start()
        
        isRecording = true
        recordingStartTime = Date()
        
        print("âœ… Ð—Ð°Ð¿Ð¸ÑÑŒ Ð½Ð°Ñ‡Ð°Ð»Ð°ÑÑŒ!")
        print("   ðŸ“º Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð·Ð²ÑƒÐº: Ð·Ð°Ñ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ")
        print("   ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½")
    }
    
    func stopRecording() {
        guard isRecording else {
            print("âš ï¸  Ð—Ð°Ð¿Ð¸ÑÑŒ Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°")
            return
        }
        
        print("\nâ¹ï¸  ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ...")
        
        Task {
            try? await stream?.stopCapture()
            stream = nil
        }
        
        microphoneEngine?.stop()
        microphoneEngine?.inputNode.removeTap(onBus: 0)
        microphoneEngine = nil
        
        if let startTime = recordingStartTime {
            let duration = Date().timeIntervalSince(startTime)
            print("â±ï¸  Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: \(formatDuration(duration))")
        }
        
        if let audioFile = audioFile {
            let filename = audioFile.url.lastPathComponent
            let fileSize = getFileSize(audioFile.url)
            print("âœ… ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: \(filename)")
            print("   Ð Ð°Ð·Ð¼ÐµÑ€: \(fileSize)")
        }
        
        if let systemFile = systemAudioFile {
            let filename = systemFile.url.lastPathComponent
            let fileSize = getFileSize(systemFile.url)
            print("âœ… Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾: \(filename)")
            print("   Ð Ð°Ð·Ð¼ÐµÑ€: \(fileSize)")
        }
        
        print("ðŸ“‚ ÐŸÐ°Ð¿ÐºÐ°: \(outputDirectory.path)")
        
        isRecording = false
        audioFile = nil
        systemAudioFile = nil
        recordingStartTime = nil
        
        onRecordingStopped?()
    }
    
    // MARK: - Private Methods
    
    private func setupMicrophone() throws {
        microphoneEngine = AVAudioEngine()
        guard let engine = microphoneEngine else { return }
        
        let inputNode = engine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        
        print("ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: \(format.sampleRate)Hz, \(format.channelCount) ÐºÐ°Ð½Ð°Ð»Ð¾Ð²")
        
        // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ tap Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: format) { [weak self] buffer, _ in
            self?.writeMicrophoneBuffer(buffer)
        }
    }
    
    private func writeMicrophoneBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = audioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°: \(error.localizedDescription)")
            }
        }
    }
    
    private func writeSystemAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = systemAudioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾: \(error.localizedDescription)")
            }
        }
    }
    
    private func createAudioFiles() throws {
        let timestamp = ISO8601DateFormatter().string(from: Date())
            .replacingOccurrences(of: ":", with: "-")
            .replacingOccurrences(of: ".", with: "-")
            .prefix(19)
    
        // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        guard let micFormat = microphoneEngine?.inputNode.outputFormat(forBus: 0) else {
            throw NSError(domain: "DualAudioRecorder", code: 1,
                         userInfo: [NSLocalizedDescriptionKey: "ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°"])
        }

        // Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
        let micFilename = "microphone_\(timestamp).wav"
        let micURL = outputDirectory.appendingPathComponent(micFilename)
        audioFile = try AVAudioFile(forWriting: micURL, settings: micFormat.settings)
        print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½ Ñ„Ð°Ð¹Ð» Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°: \(micFilename)")

        // Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ (ÑÑ‚ÐµÑ€ÐµÐ¾)
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 48000.0,
            AVNumberOfChannelsKey: 2,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]
    
        let sysFilename = "system_\(timestamp).wav"
        let sysURL = outputDirectory.appendingPathComponent(sysFilename)
        systemAudioFile = try AVAudioFile(forWriting: sysURL, settings: settings)
        print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½ Ñ„Ð°Ð¹Ð» ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: \(sysFilename)")
    }
    
    private func getFileSize(_ url: URL) -> String {
        guard let attributes = try? FileManager.default.attributesOfItem(atPath: url.path),
              let fileSize = attributes[.size] as? Int64 else {
            return "unknown"
        }
        
        let formatter = ByteCountFormatter()
        formatter.countStyle = .file
        return formatter.string(fromByteCount: fileSize)
    }
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    deinit {
        if isRecording {
            stopRecording()
        }
    }
}

// MARK: - SCStreamDelegate

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("âŒ ÐŸÐ¾Ñ‚Ð¾Ðº Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹: \(error.localizedDescription)")
        stopRecording()
    }
}

// MARK: - SCStreamOutput

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamOutput {
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard isRecording, type == .audio else { return }
        
        // ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ CMSampleBuffer Ð² AVAudioPCMBuffer
        guard let audioBuffer = createPCMBuffer(from: sampleBuffer) else { return }
        
        writeSystemAudioBuffer(audioBuffer)
    }
    
    private func createPCMBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer),
              let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) else {
            return nil
        }
        
        let format = AVAudioFormat(streamDescription: audioStreamBasicDescription)!
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        CMSampleBufferCopyPCMDataIntoAudioBufferList(
            sampleBuffer,
            at: 0,
            frameCount: Int32(frameCount),
            into: buffer.mutableAudioBufferList
        )
        
        return buffer
    }
}
