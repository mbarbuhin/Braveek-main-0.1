import Foundation
import AVFoundation
import ScreenCaptureKit
import CoreAudio

@available(macOS 13.0, *)
class DualAudioRecorder: NSObject {
    // MARK: - Properties
    
    private var stream: SCStream?
    private var microphoneEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    private var systemAudioFile: AVAudioFile?

    private var isRecording = false
    private var recordingStartTime: Date?
    private var currentRecordingBaseName: String?

    private let microphoneDirectory: URL
    private let systemDirectory: URL
    private let mixDirectory: URL
    private let queue = DispatchQueue(label: "com.meetingrecorder.audio", qos: .userInitiated)

    var onRecordingStopped: (() -> Void)?

    // MARK: - Init

    override init() {
        let paths = AppPaths.shared
        self.microphoneDirectory = paths.microphoneRecordingsDirectory
        self.systemDirectory = paths.systemRecordingsDirectory
        self.mixDirectory = paths.mixedRecordingsDirectory

        super.init()

        print("üéôÔ∏è  DualAudioRecorder –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print("üìÅ –ü–∞–ø–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:")
        print("   üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω: \(microphoneDirectory.path)")
        print("   üíª –°–∏—Å—Ç–µ–º–∞: \(systemDirectory.path)")
        print("   üéß –ú–∏–∫—Å—ã: \(mixDirectory.path)")
    }
    
    // MARK: - Public Methods
    
    func startRecording() async throws {
        guard !isRecording else {
            print("‚ö†Ô∏è  –ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥—ë—Ç")
            return
        }
        
        print("\nüé¨ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å...")
        
        // 1. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
        try setupMicrophone()
        
        // 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∞—É–¥–∏–æ
        let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
        
        // 3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ
        let config = SCStreamConfiguration()
        config.capturesAudio = true
        config.sampleRate = 48000
        config.channelCount = 2
        
        // –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä (–∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—Å—ë —Å–∏—Å—Ç–µ–º–Ω–æ–µ –∞—É–¥–∏–æ)
        let filter = SCContentFilter(display: content.displays.first!, excludingWindows: [])
        
        // 4. –°–æ–∑–¥–∞—ë–º –ø–æ—Ç–æ–∫ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ
        stream = SCStream(filter: filter, configuration: config, delegate: self)
        
        // 5. –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–ø–∏—Å–∏
        try createAudioFiles()
        
        // 6. –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–≤–æ–¥ –∞—É–¥–∏–æ
        try stream?.addStreamOutput(self, type: .audio, sampleHandlerQueue: queue)
        
        // 7. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ
        try await stream?.startCapture()
        
        // 8. –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
        try microphoneEngine?.start()
        
        isRecording = true
        recordingStartTime = Date()
        
        print("‚úÖ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å!")
        print("   üì∫ –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç—Å—è")
        print("   üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω: –∞–∫—Ç–∏–≤–µ–Ω")
    }
    
    func stopRecording() {
        guard isRecording else {
            print("‚ö†Ô∏è  –ó–∞–ø–∏—Å—å –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞")
            return
        }

        print("\n‚èπÔ∏è  –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...")

        let microphoneURL = audioFile?.url
        let systemURL = systemAudioFile?.url
        let baseName = currentRecordingBaseName

        Task {
            try? await stream?.stopCapture()
            stream = nil
        }

        microphoneEngine?.stop()
        microphoneEngine?.inputNode.removeTap(onBus: 0)
        microphoneEngine = nil
        
        if let startTime = recordingStartTime {
            let duration = Date().timeIntervalSince(startTime)
            print("‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: \(formatDuration(duration))")
        }
        
        if let audioFile = audioFile {
            let filename = audioFile.url.lastPathComponent
            let fileSize = getFileSize(audioFile.url)
            print("‚úÖ –ú–∏–∫—Ä–æ—Ñ–æ–Ω —Å–æ—Ö—Ä–∞–Ω—ë–Ω: \(filename)")
            print("   –†–∞–∑–º–µ—Ä: \(fileSize)")
        }
        
        if let systemFile = systemAudioFile {
            let filename = systemFile.url.lastPathComponent
            let fileSize = getFileSize(systemFile.url)
            print("‚úÖ –°–∏—Å—Ç–µ–º–Ω–æ–µ –∞—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: \(filename)")
            print("   –†–∞–∑–º–µ—Ä: \(fileSize)")
        }

        print("üìÇ –ü–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è:")
        print("   üé§ \(microphoneDirectory.lastPathComponent): \(microphoneDirectory.path)")
        print("   üíª \(systemDirectory.lastPathComponent): \(systemDirectory.path)")
        print("   üéß \(mixDirectory.lastPathComponent): \(mixDirectory.path)")

        if let microphoneURL, let systemURL, let baseName {
            print("üéöÔ∏è –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–≤–µ–¥–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫—É –¥–ª—è \(baseName)...")
            Task.detached { [weak self] in
                await self?.mixDownRecordings(
                    microphoneURL: microphoneURL,
                    systemURL: systemURL,
                    baseName: baseName
                )
            }
        }

        isRecording = false
        audioFile = nil
        systemAudioFile = nil
        recordingStartTime = nil
        currentRecordingBaseName = nil

        onRecordingStopped?()
    }
    
    // MARK: - Private Methods
    
    private func setupMicrophone() throws {
        microphoneEngine = AVAudioEngine()
        guard let engine = microphoneEngine else { return }
        
        let inputNode = engine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        
        print("üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω: \(format.sampleRate)Hz, \(format.channelCount) –∫–∞–Ω–∞–ª–æ–≤")
        
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap –¥–ª—è –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: format) { [weak self] buffer, _ in
            self?.writeMicrophoneBuffer(buffer)
        }
    }
    
    private func writeMicrophoneBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = audioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: \(error.localizedDescription)")
            }
        }
    }
    
    private func writeSystemAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard isRecording, let file = systemAudioFile else { return }
        
        queue.async {
            do {
                try file.write(from: buffer)
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ: \(error.localizedDescription)")
            }
        }
    }
    
    private func createAudioFiles() throws {
        let timestamp = ISO8601DateFormatter().string(from: Date())
            .replacingOccurrences(of: ":", with: "-")
            .replacingOccurrences(of: ".", with: "-")
            .prefix(19)
        let baseName = String(timestamp)
        currentRecordingBaseName = baseName

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        guard let micFormat = microphoneEngine?.inputNode.outputFormat(forBus: 0) else {
            throw NSError(domain: "DualAudioRecorder", code: 1,
                         userInfo: [NSLocalizedDescriptionKey: "–ù–µ –ø–æ–ª—É—á–µ–Ω —Ñ–æ—Ä–º–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"])
        }

        // –§–∞–π–ª –¥–ª—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        let micFilename = "microphone_\(baseName).wav"
        let micURL = microphoneDirectory.appendingPathComponent(micFilename)
        audioFile = try AVAudioFile(forWriting: micURL, settings: micFormat.settings)
        print("üìù –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: \(micFilename)")

        // –§–∞–π–ª –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ (—Å—Ç–µ—Ä–µ–æ)
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 48000.0,
            AVNumberOfChannelsKey: 2,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]

        let sysFilename = "system_\(baseName).wav"
        let sysURL = systemDirectory.appendingPathComponent(sysFilename)
        systemAudioFile = try AVAudioFile(forWriting: sysURL, settings: settings)
        print("üìù –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª —Å–∏—Å—Ç–µ–º—ã: \(sysFilename)")
    }

    private func mixDownRecordings(microphoneURL: URL, systemURL: URL, baseName: String) async {
        print("üéöÔ∏è –°–≤–µ–¥–µ–Ω–∏–µ –¥–æ—Ä–æ–∂–µ–∫ –¥–ª—è \(baseName) –∑–∞–ø—É—â–µ–Ω–æ...")
        do {
            let outputURL = try await mixAudioFiles(
                microphoneURL: microphoneURL,
                systemURL: systemURL,
                baseName: baseName
            )
            let fileSize = getFileSize(outputURL)
            print("üéß –°–≤–µ–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: \(outputURL.lastPathComponent)")
            print("   –†–∞–∑–º–µ—Ä: \(fileSize)")
            print("   –ü—É—Ç—å: \(outputURL.path)")
            print("‚òÅÔ∏è –û—Ç–ø—Ä–∞–≤–∫–∞ –º–∏–∫—Å–∞ –≤ Supabase (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)...")

            Task.detached(priority: .background) {
                do {
                    try await SupabaseUploader.shared.uploadMix(at: outputURL, baseName: baseName)
                    print("üì§ Supabase: –º–∏–∫—Å \(outputURL.lastPathComponent) –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
                } catch {
                    print("‚ö†Ô∏è Supabase: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å \(outputURL.lastPathComponent): \(error.localizedDescription)")
                    print("   –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –æ—Ñ–ª–∞–π–Ω, —Ñ–∞–π–ª –¥–æ—Å—Ç—É–ø–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ.")
                }
            }
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ —Å–≤–µ–¥–µ–Ω–∏—è –¥–æ—Ä–æ–∂–µ–∫: \(error.localizedDescription)")
        }
    }

    private func mixAudioFiles(microphoneURL: URL, systemURL: URL, baseName: String) async throws -> URL {
        let outputURL = mixDirectory.appendingPathComponent("mix_\(baseName).m4a")
        if FileManager.default.fileExists(atPath: outputURL.path) {
            try FileManager.default.removeItem(at: outputURL)
        }

        let composition = AVMutableComposition()

        let microphoneAsset = AVURLAsset(url: microphoneURL)
        let systemAsset = AVURLAsset(url: systemURL)

        let microphoneTrack = try await loadAudioTrack(from: microphoneAsset)
        let systemTrack = try await loadAudioTrack(from: systemAsset)

        guard let microphoneCompositionTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ), let systemCompositionTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            throw NSError(
                domain: "DualAudioRecorder",
                code: 3,
                userInfo: [NSLocalizedDescriptionKey: "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–æ—Ä–æ–∂–∫–∏ –¥–ª—è —Å–≤–µ–¥–µ–Ω–∏—è"]
            )
        }

        let microphoneDuration = try await loadDuration(for: microphoneAsset)
        let systemDuration = try await loadDuration(for: systemAsset)

        try microphoneCompositionTrack.insertTimeRange(
            CMTimeRange(start: .zero, duration: microphoneDuration),
            of: microphoneTrack,
            at: .zero
        )

        try systemCompositionTrack.insertTimeRange(
            CMTimeRange(start: .zero, duration: systemDuration),
            of: systemTrack,
            at: .zero
        )

        let audioMix = AVMutableAudioMix()
        let microphoneParameters = AVMutableAudioMixInputParameters(track: microphoneCompositionTrack)
        microphoneParameters.setVolume(1.0, at: .zero)
        let systemParameters = AVMutableAudioMixInputParameters(track: systemCompositionTrack)
        systemParameters.setVolume(1.0, at: .zero)
        audioMix.inputParameters = [microphoneParameters, systemParameters]

        guard let exporter = AVAssetExportSession(
            asset: composition,
            presetName: AVAssetExportPresetAppleM4A
        ) else {
            throw NSError(
                domain: "DualAudioRecorder",
                code: 4,
                userInfo: [NSLocalizedDescriptionKey: "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä –¥–ª—è —Å–≤–µ–¥–µ–Ω–∏—è"]
            )
        }

        exporter.audioMix = audioMix
        exporter.outputURL = outputURL
        exporter.outputFileType = .m4a

        let maxDuration = CMTimeMaximum(microphoneDuration, systemDuration)
        if maxDuration.isNumeric && maxDuration.isValid && !maxDuration.isIndefinite {
            exporter.timeRange = CMTimeRange(start: .zero, duration: maxDuration)
        }

        try await export(exporter)
        return outputURL
    }

    private func loadAudioTrack(from asset: AVURLAsset) async throws -> AVAssetTrack {
        try await withCheckedThrowingContinuation { continuation in
            asset.loadValuesAsynchronously(forKeys: ["tracks"]) {
                var error: NSError?
                let status = asset.statusOfValue(forKey: "tracks", error: &error)
                switch status {
                case .loaded:
                    if let track = asset.tracks(withMediaType: .audio).first {
                        continuation.resume(returning: track)
                    } else {
                        continuation.resume(throwing: NSError(
                            domain: "DualAudioRecorder",
                            code: 5,
                            userInfo: [NSLocalizedDescriptionKey: "–ê—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"]
                        ))
                    }
                case .failed:
                    continuation.resume(throwing: error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 6,
                        userInfo: [NSLocalizedDescriptionKey: "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ—Ä–æ–∂–∫—É"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 7,
                        userInfo: [NSLocalizedDescriptionKey: "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ—Ä–æ–∂–∫–∏ –æ—Ç–º–µ–Ω–µ–Ω–∞"]
                    ))
                default:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 8,
                        userInfo: [NSLocalizedDescriptionKey: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Ä–æ–∂–∫–∏"]
                    ))
                }
            }
        }
    }

    private func loadDuration(for asset: AVURLAsset) async throws -> CMTime {
        try await withCheckedThrowingContinuation { continuation in
            asset.loadValuesAsynchronously(forKeys: ["duration"]) {
                var error: NSError?
                let status = asset.statusOfValue(forKey: "duration", error: &error)
                switch status {
                case .loaded:
                    continuation.resume(returning: asset.duration)
                case .failed:
                    continuation.resume(throwing: error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 9,
                        userInfo: [NSLocalizedDescriptionKey: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 10,
                        userInfo: [NSLocalizedDescriptionKey: "–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–º–µ–Ω–µ–Ω–æ"]
                    ))
                default:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 11,
                        userInfo: [NSLocalizedDescriptionKey: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"]
                    ))
                }
            }
        }
    }

    private func export(_ exporter: AVAssetExportSession) async throws {
        try await withCheckedThrowingContinuation { continuation in
            exporter.exportAsynchronously {
                switch exporter.status {
                case .completed:
                    continuation.resume()
                case .failed:
                    continuation.resume(throwing: exporter.error ?? NSError(
                        domain: "DualAudioRecorder",
                        code: 12,
                        userInfo: [NSLocalizedDescriptionKey: "–≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π"]
                    ))
                case .cancelled:
                    continuation.resume(throwing: NSError(
                        domain: "DualAudioRecorder",
                        code: 13,
                        userInfo: [NSLocalizedDescriptionKey: "–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç–º–µ–Ω—ë–Ω"]
                    ))
                default:
                    break
                }
            }
        }
    }
    
    private func getFileSize(_ url: URL) -> String {
        guard let attributes = try? FileManager.default.attributesOfItem(atPath: url.path),
              let fileSize = attributes[.size] as? Int64 else {
            return "unknown"
        }
        
        let formatter = ByteCountFormatter()
        formatter.countStyle = .file
        return formatter.string(fromByteCount: fileSize)
    }
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    deinit {
        if isRecording {
            stopRecording()
        }
    }
}

// MARK: - SCStreamDelegate

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("‚ùå –ü–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å –æ—à–∏–±–∫–æ–π: \(error.localizedDescription)")
        stopRecording()
    }
}

// MARK: - SCStreamOutput

@available(macOS 13.0, *)
extension DualAudioRecorder: SCStreamOutput {
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard isRecording, type == .audio else { return }
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º CMSampleBuffer –≤ AVAudioPCMBuffer
        guard let audioBuffer = createPCMBuffer(from: sampleBuffer) else { return }
        
        writeSystemAudioBuffer(audioBuffer)
    }
    
    private func createPCMBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer),
              let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) else {
            return nil
        }
        
        let format = AVAudioFormat(streamDescription: audioStreamBasicDescription)!
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        CMSampleBufferCopyPCMDataIntoAudioBufferList(
            sampleBuffer,
            at: 0,
            frameCount: Int32(frameCount),
            into: buffer.mutableAudioBufferList
        )
        
        return buffer
    }
}
